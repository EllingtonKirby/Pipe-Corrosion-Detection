{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "from torchvision.transforms import functional as VF\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "from torchvision import models, datasets, tv_tensors\n",
    "from torchvision.transforms import v2\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellsDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = False\n",
    "        self.scaler = RobustScaler()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "def build_train_dataframe():\n",
    "  if os.path.exists('./inputs/x_train_df.csv'):\n",
    "      return pd.read_csv('inputs/x_train_df.csv')\n",
    "\n",
    "  data_dir = './train/images/'\n",
    "  data_dict = []\n",
    "  pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "  for i, filename in enumerate(os.listdir(data_dir)):\n",
    "      example = np.load(data_dir + filename)\n",
    "      match = re.match(pattern, filename)\n",
    "      if match:\n",
    "          well_number = int(match.group(1))  # Extract well number\n",
    "          patch_number = int(match.group(2)) # Extract patch number\n",
    "      else:\n",
    "          print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "      data_dict.append((filename, well_number, patch_number, example.flatten()))\n",
    "\n",
    "  df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "\n",
    "  df_y = pd.read_csv('train/y_train.csv')\n",
    "  df_y['Unnamed: 0'] = df_y['Unnamed: 0'] + '.npy'\n",
    "\n",
    "  # Create single dataframe with data and labels as lists\n",
    "  merged = pd.merge(df, df_y, how='left', left_on='filename', right_on='Unnamed: 0')\n",
    "  data_columns = [str(i) for i in range(1296)]\n",
    "  labeled_data = merged[data_columns].to_numpy()\n",
    "  # Convert missing labels to all zeros\n",
    "  labeled_data = np.nan_to_num(labeled_data)\n",
    "  merged['labels'] = labeled_data.tolist()\n",
    "  merged = merged.rename(columns={'Unnamed: 0':'label_name'})\n",
    "  merged = merged.fillna(0.0)\n",
    "\n",
    "  data = torch.from_numpy(np.vstack(merged['data'].to_numpy(dtype=np.ndarray)))\n",
    "  # Remove corruputed samples\n",
    "  outliers = ((data.min(dim=1, keepdim=True).values == -999.2500) == True).flatten()\n",
    "\n",
    "  merged = merged.drop(merged.loc[outliers.tolist()].index)\n",
    "  merged.to_csv(path_or_buf='./inputs/x_train.csv')\n",
    "  return merged.sort_values(by=['well_number','patch_number'])\n",
    "\n",
    "def build_test_dataframe():\n",
    "  data_dir = './test/images/'\n",
    "  data_dict = []\n",
    "  pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "  for i, filename in enumerate(os.listdir(data_dir)):\n",
    "      example = np.load(data_dir + filename)\n",
    "      match = re.match(pattern, filename)\n",
    "      name = filename[:-4]\n",
    "      if match:\n",
    "          well_number = int(match.group(1))  # Extract well number\n",
    "          patch_number = int(match.group(2)) # Extract patch number\n",
    "      else:\n",
    "          print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "      data_dict.append((name, well_number, patch_number, example.flatten()))\n",
    "\n",
    "  df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "  return df.sort_values(by=['well_number','patch_number'])\n",
    "\n",
    "def build_dataloaders(test_dataframe, train_dataframe, permutation):\n",
    "    test_data = torch.from_numpy(np.vstack(test_dataframe['data'].to_numpy()))\n",
    "    test_data = torch.nan_to_num(test_data)\n",
    "    X_names = np.vstack(test_dataframe['filename'].to_numpy())\n",
    "\n",
    "    train_data = torch.from_numpy(np.vstack(train_dataframe['data'].to_numpy()))\n",
    "    train_data = torch.nan_to_num(train_data)\n",
    "    p = permutation\n",
    "    train_data = train_data[p]\n",
    "\n",
    "    offset = int(len(train_data) * .8)\n",
    "    X_train = train_data[:offset]\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(train_data)\n",
    "\n",
    "    X_test = torch.tensor(scaler.transform(test_data)).float().reshape(-1, 1, 36, 36)\n",
    "    X_train = torch.tensor(scaler.transform(train_data)).float().reshape(-1, 1, 36, 36)\n",
    "    return X_test, X_names, X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet\n",
    "import baseline\n",
    "import json\n",
    "# model = unet.UNet(n_channels=1, n_classes=1)\n",
    "model = baseline.Baseline()\n",
    "model.load_state_dict(torch.load('./baseline_model_1.pt', map_location=torch.device('cpu')))\n",
    "test_df = build_test_dataframe()\n",
    "train_df = build_train_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_set_permutation.json') as f:\n",
    "  permutation = json.load(f)\n",
    "X_test, X_names, X_train = build_dataloaders(test_df, train_df, permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(TensorDataset(X_test), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2538it [00:09, 274.19it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "for index, x in tqdm(enumerate(test_dl)):\n",
    "  out = model(x[0])\n",
    "  preds = (F.sigmoid(out) > .5)*1.\n",
    "  name = X_names[index][0]\n",
    "  predictions[name] = preds.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame.from_dict(predictions, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv('KIRBY_predictions_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipe_id_dataloaders(train_dataframe, valid_dataframe, p):\n",
    "  data = torch.from_numpy(np.vstack(train_dataframe['data'].to_numpy()))\n",
    "  data = torch.nan_to_num(data)\n",
    "  labels = torch.from_numpy(np.vstack(train_dataframe['labels'].to_numpy()))\n",
    "\n",
    "  valid_data = torch.from_numpy(np.vstack(valid_dataframe['data'].to_numpy()))\n",
    "  valid_data = torch.nan_to_num(valid_data)\n",
    "  valid_labels = torch.from_numpy(np.vstack(valid_dataframe['well_number'].to_numpy())).squeeze() - 1\n",
    "  X_names = np.vstack(valid_dataframe['filename'].to_numpy())\n",
    "\n",
    "  data = data[p]\n",
    "  offset = int(len(data) * .5)\n",
    "\n",
    "  X_train, X_valid = data[:offset], valid_data\n",
    "  Y_train, Y_valid = labels[:offset], valid_labels\n",
    "\n",
    "  scaler = RobustScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = torch.tensor(scaler.transform(X_train)).float().reshape(-1, 1, 36, 36)\n",
    "  X_valid = torch.tensor(scaler.transform(X_valid)).float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "  return X_valid, X_train, Y_train, X_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipe_identifier\n",
    "import json\n",
    "with open('./classification_train_set_permutation.json') as f:\n",
    "  p = json.load(f)\n",
    "X_test, X_train, Y_train, X_names = get_pipe_id_dataloaders(build_train_dataframe(), build_test_dataframe(), p)\n",
    "model = pipe_identifier.PipeIdentifier(num_classes=15)\n",
    "model.load_state_dict(torch.load('./well_classifier_1.pt', map_location=torch.device('cpu')))\n",
    "pipe_id_dataloader = DataLoader(TensorDataset(X_test), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2538it [00:17, 148.96it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "for index, x in tqdm(enumerate(pipe_id_dataloader)):\n",
    "  out = model(x[0])\n",
    "  preds = torch.argmax(F.softmax(out, dim=1))\n",
    "  name = X_names[index][0]\n",
    "  predictions[name] = preds.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame.from_dict(predictions, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     2377\n",
       "8      137\n",
       "9       16\n",
       "10       7\n",
       "14       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4717it [00:31, 150.14it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "for index, x in tqdm(enumerate(X_train)):\n",
    "  out = model(x.unsqueeze(dim=0))\n",
    "  preds = torch.argmax(F.softmax(out, dim=1))\n",
    "  name = Y_train[index][0]\n",
    "  predictions[name] = preds.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame.from_dict(predictions, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     4699\n",
       "8       15\n",
       "14       2\n",
       "9        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
