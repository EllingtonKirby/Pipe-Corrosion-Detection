{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "from torchvision.transforms import functional as VF\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "from torchvision import models, datasets, tv_tensors\n",
    "from torchvision.transforms import v2\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import data_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet\n",
    "import baseline\n",
    "import json\n",
    "# model = unet.UNet(n_channels=1, n_classes=1)\n",
    "model = baseline.Baseline()\n",
    "model.load_state_dict(torch.load('./checkpoints/baseline/baseline_model_3.pt', map_location=torch.device('cpu')))\n",
    "test_df = data_pipeline.build_test_dataframe(use_processed_images=False)\n",
    "train_df = data_pipeline.build_dataframe(use_processed_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_names, X_train = data_pipeline.build_test_dataloaders(test_df, train_df, apply_scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(TensorDataset(X_test), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = X_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAkACQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6KKKKKKKKKKKKKKKKKKKKKKKK/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACQAAAAkCAAAAADEa8dEAAAAIUlEQVR4AWP8z0AYMBFWwsAwqmg0CEZTATCnjGaEYR4EAO6cAUe3/o/iAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=36x36>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1 = F.sigmoid(model(input_1))\n",
    "pred_1 = (out_1 > .5)*1.\n",
    "VF.to_pil_image(pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5008, 0.5001, 0.5001,  ..., 0.5002, 0.5001, 0.5004],\n",
       "         [0.5006, 0.5002, 0.5001,  ..., 0.5001, 0.5001, 0.5002],\n",
       "         [0.5004, 0.5002, 0.5001,  ..., 0.5001, 0.5001, 0.5001],\n",
       "         ...,\n",
       "         [0.5002, 0.5001, 0.5001,  ..., 0.5000, 0.5001, 0.5001],\n",
       "         [0.5002, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5001],\n",
       "         [0.5007, 0.5001, 0.5001,  ..., 0.5001, 0.5001, 0.5004]]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2538it [00:09, 270.15it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "for index, x in tqdm(enumerate(test_dl)):\n",
    "  out = model(x[0])\n",
    "  preds = (F.sigmoid(out) > .5)*1.\n",
    "  name = X_names[index][0]\n",
    "  predictions[name] = preds.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame.from_dict(predictions, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv('./outputs/KIRBY_predictions_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAkACQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6KKKKKKKKKKKKKKKKKKKKKKKK/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACQAAAAkCAAAAADEa8dEAAAAIUlEQVR4AWP8z0AYMBFWwsAwqmg0CEZTATCnjGaEYR4EAO6cAUe3/o/iAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=36x36>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [i for i in range(1296)]\n",
    "VF.to_pil_image(torch.tensor(preds_df[cols].iloc[100].to_numpy().reshape(36, 36)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pipe_id_dataloaders(train_dataframe, valid_dataframe):\n",
    "  data = torch.from_numpy(np.vstack(train_dataframe['data'].to_numpy()))\n",
    "  data = torch.nan_to_num(data)\n",
    "  labels = torch.from_numpy(np.vstack(train_dataframe['labels'].to_numpy()))\n",
    "\n",
    "  valid_data = torch.from_numpy(np.vstack(valid_dataframe['data'].to_numpy()))\n",
    "  valid_data = torch.nan_to_num(valid_data)\n",
    "  valid_labels = torch.from_numpy(np.vstack(valid_dataframe['well_number'].to_numpy())).squeeze() - 1\n",
    "  X_names = np.vstack(valid_dataframe['filename'].to_numpy())\n",
    "\n",
    "  X_train, X_valid = data.float().reshape(-1, 1, 36, 36), valid_data.float().reshape(-1, 1, 36, 36)\n",
    "  Y_train, Y_valid = labels, valid_labels\n",
    "\n",
    "  return X_train, X_valid, Y_train, Y_valid, X_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pipe_identifier\n",
    "import json\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid, X_names = get_pipe_id_dataloaders(data_pipeline.build_dataframe(), data_pipeline.build_test_dataframe())\n",
    "model = pipe_identifier.PipeIdentifier(num_classes=15)\n",
    "model.load_state_dict(torch.load('./well_classifier_3.pt', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_id_dataloader = DataLoader(TensorDataset(X_valid), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2538it [00:18, 139.39it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "for index, x in tqdm(enumerate(pipe_id_dataloader)):\n",
    "  out = model(x[0])\n",
    "  preds = torch.argmax(F.softmax(out, dim=1))\n",
    "  name = X_names[index][0]\n",
    "  predictions[name] = preds.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame.from_dict(predictions, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    2334\n",
       "9       97\n",
       "10      79\n",
       "2       21\n",
       "5        4\n",
       "6        2\n",
       "4        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9670it [01:11, 135.99it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "for index, x in tqdm(enumerate(X_train)):\n",
    "  out = model(x.unsqueeze(dim=0))\n",
    "  preds = torch.argmax(F.softmax(out, dim=1))\n",
    "  name = Y_train[index][0]\n",
    "  predictions[name] = preds.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame.from_dict(predictions, orient='index')\n",
    "preds_df[0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    5081\n",
       "3     2197\n",
       "11    1517\n",
       "7      438\n",
       "10     190\n",
       "2      162\n",
       "6       74\n",
       "1        8\n",
       "15       2\n",
       "9        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unet 5  - 0.38 validation IoU - Two Down Convs + All Images Scaled + Bulk Augments\n",
    "- Unet 8  - 0.64 validation IoU - Two Down Convs + No Scaling + Random Augments\n",
    "- Unet 9  - 0.63 validation IoU - Three down convs + No Scaling + Random Augments\n",
    "- Unet 10 - 0.57 validation IoU - One down conv + No Scaling + Random Augments\n",
    "\n",
    "\n",
    "However on the test set our results are much worse. But it appears that the scaling does not make much of a difference\n",
    "\n",
    "When looking at the output we are just predicting 0.0 for everything, and that is how we wind up with an unchanged score\n",
    "\n",
    "- Unet 11 - 0.59 train IoU - Two Down Convs + No Scaling + Random Augments + No Train Test Split\n",
    "  - predicts 481 total 1.0... probably not it either\n",
    "- Unet 12 - 0.58 train IoU - Two Down Convs + Robust Scaler on full Train Set + Random Augments + No Train Test Split\n",
    "  - predicts 3091 1.0 values, maybe this is the next one to test?\n",
    "- Unet 13 - 0.66 train IoU - Full Unet + Robust Scaler on full Train Set + Random Augments + No Train Test Split\n",
    "  - predicts 41 1.0 values... not it..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
