{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "from torchvision.transforms import functional as VF\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "from torchvision import models, datasets, tv_tensors\n",
    "from torchvision.transforms import v2\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data - Fill NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './train/images/'\n",
    "data_dict = []\n",
    "pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "for i, filename in enumerate(os.listdir(data_dir)):\n",
    "  example = np.load(data_dir + filename)\n",
    "  match = re.match(pattern, filename)\n",
    "  if match:\n",
    "    well_number = int(match.group(1))  # Extract well number\n",
    "    patch_number = int(match.group(2)) # Extract patch number\n",
    "  else:\n",
    "    print(\"Filename format does not match the expected pattern.\")  \n",
    "  \n",
    "  data_dict.append((filename, well_number, patch_number, example.flatten()))\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_csv('train/y_train.csv')\n",
    "df_y['Unnamed: 0'] = df_y['Unnamed: 0'] + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, df_y, how='left', left_on='filename', right_on='Unnamed: 0')\n",
    "data_columns = [str(i) for i in range(1296)]\n",
    "labeled_data = merged[data_columns].to_numpy()\n",
    "merged['labels'] = labeled_data.tolist()\n",
    "merged = merged.rename(columns={'Unnamed: 0':'label_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_wells = merged[merged['label_name'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "      <th>1280</th>\n",
       "      <th>1281</th>\n",
       "      <th>1282</th>\n",
       "      <th>1283</th>\n",
       "      <th>1284</th>\n",
       "      <th>1285</th>\n",
       "      <th>1286</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        3    4    5    6    7    8    9   10   11   16  ...  1277  1278  1279  \\\n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   1.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   1.0   \n",
       "6     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   1.0   \n",
       "9     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   1.0   \n",
       "10    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "2530  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2533  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   1.0   \n",
       "2534  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   1.0   \n",
       "2535  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   1.0   \n",
       "2537  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   1.0   \n",
       "\n",
       "      1280  1281  1282  1283  1284  1285  1286  \n",
       "3      1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      1.0   1.0   1.0   0.0   0.0   0.0   0.0  \n",
       "6      1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "9      1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "10     1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  \n",
       "2530   1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2533   1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2534   1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2535   1.0   1.0   1.0   0.0   0.0   0.0   0.0  \n",
       "2537   1.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[671 rows x 721 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This confirms that all values for which we have a label have at least one value above 0.0\n",
    "# So we can fill missing values with 0.0\n",
    "\n",
    "non_zero_columns = (matched_wells[data_columns] != 0.0).any()\n",
    "non_zero_columns = non_zero_columns[non_zero_columns == True]\n",
    "matched_wells[non_zero_columns.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, df_y, how='left', left_on='filename', right_on='Unnamed: 0')\n",
    "data_columns = [str(i) for i in range(1296)]\n",
    "labeled_data = merged[data_columns].to_numpy()\n",
    "labeled_data = np.nan_to_num(labeled_data)\n",
    "merged['labels'] = labeled_data.tolist()\n",
    "merged = merged.rename(columns={'Unnamed: 0':'label_name'})\n",
    "merged = merged.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for outlier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2538, 1296])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.from_numpy(np.vstack(merged['data'].to_numpy(dtype=np.ndarray)))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 175.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        2363.]),\n",
       " array([-9.99250000e+02, -8.99326050e+02, -7.99402039e+02, -6.99478088e+02,\n",
       "        -5.99554077e+02, -4.99630096e+02, -3.99706116e+02, -2.99782166e+02,\n",
       "        -1.99858170e+02, -9.99341965e+01, -1.02152824e-02]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.min(dim=1, keepdim=True).values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2538])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = ((data.min(dim=1, keepdim=True).values == -999.2500) == True).flatten()\n",
    "outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(merged.loc[outliers.tolist()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellsDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = False\n",
    "        self.scaler = RobustScaler()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "def build_dataframe():\n",
    "    data_dir = './train/images/'\n",
    "    data_dict = []\n",
    "    pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "    for i, filename in enumerate(os.listdir(data_dir)):\n",
    "        example = np.load(data_dir + filename)\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            well_number = int(match.group(1))  # Extract well number\n",
    "            patch_number = int(match.group(2)) # Extract patch number\n",
    "        else:\n",
    "            print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "        data_dict.append((filename, well_number, patch_number, example.flatten()))\n",
    "\n",
    "    df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "\n",
    "    df_y = pd.read_csv('train/y_train.csv')\n",
    "    df_y['Unnamed: 0'] = df_y['Unnamed: 0'] + '.npy'\n",
    "\n",
    "    # Create single dataframe with data and labels as lists\n",
    "    merged = pd.merge(df, df_y, how='left', left_on='filename', right_on='Unnamed: 0')\n",
    "    data_columns = [str(i) for i in range(1296)]\n",
    "    labeled_data = merged[data_columns].to_numpy()\n",
    "    # Convert missing labels to all zeros\n",
    "    labeled_data = np.nan_to_num(labeled_data)\n",
    "    merged['labels'] = labeled_data.tolist()\n",
    "    merged = merged.rename(columns={'Unnamed: 0':'label_name'})\n",
    "    merged = merged.fillna(0.0)\n",
    "\n",
    "    data = torch.from_numpy(np.vstack(merged['data'].to_numpy(dtype=np.ndarray)))\n",
    "    # Remove corruputed samples\n",
    "    outliers = ((data.min(dim=1, keepdim=True).values == -999.2500) == True).flatten()\n",
    "\n",
    "    merged = merged.drop(merged.loc[outliers.tolist()].index)\n",
    "    return merged\n",
    "\n",
    "def build_dataloaders(dataframe):\n",
    "    data = torch.from_numpy(np.vstack(dataframe['data'].to_numpy()))\n",
    "    data = torch.nan_to_num(data)\n",
    "    labels = torch.from_numpy(np.vstack(dataframe['labels'].to_numpy()))\n",
    "\n",
    "    p = np.random.permutation(len(data))\n",
    "    with open('train_set_permutation.json', 'w') as f:\n",
    "        # Write permutation to file so that we can re-apply the same transform later\n",
    "        json.dump(p.tolist(), f)\n",
    "\n",
    "    data, labels = data[p], labels[p]\n",
    "\n",
    "    offset = int(len(data) * .8)\n",
    "    X_train, X_valid = data[:offset], data[offset:]\n",
    "    Y_train, Y_valid = labels[:offset].float().reshape(-1, 1, 36, 36), labels[offset:].float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = torch.tensor(scaler.transform(X_train)).float().reshape(-1, 1, 36, 36)\n",
    "    X_valid = torch.tensor(scaler.transform(X_valid)).float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "    # Applying augmentations selectively does not improve performance\n",
    "    # num_non_zero_y = torch.count_nonzero(labels[:offset], axis=1)\n",
    "    examples_to_augment = X_train\n",
    "    labels_to_augment = Y_train\n",
    "\n",
    "    rolled_x, rolled_y = [], []\n",
    "    for i in range(1, 36):\n",
    "        rolled_x.append(torch.roll(examples_to_augment, i, dims=3))\n",
    "        rolled_y.append(torch.roll(labels_to_augment, i, dims=3))\n",
    "\n",
    "    X_train, Y_train = torch.vstack((X_train, *rolled_x)), torch.vstack((Y_train, *rolled_y))\n",
    "\n",
    "    flipper = v2.RandomVerticalFlip(1)\n",
    "    X_train, Y_train = torch.vstack((X_train, flipper(examples_to_augment))), torch.vstack((Y_train, flipper(labels_to_augment)))\n",
    "\n",
    "    train_dataset = WellsDataset(X_train, Y_train, None)\n",
    "    valid_dataset = WellsDataset(X_valid, Y_valid, None)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=128)\n",
    "\n",
    "    return train_dataloader, valid_dataloader\n",
    "\n",
    "def build_test_dataframe():\n",
    "  data_dir = './test/images/'\n",
    "  data_dict = []\n",
    "  pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "  for i, filename in enumerate(os.listdir(data_dir)):\n",
    "      example = np.load(data_dir + filename)\n",
    "      match = re.match(pattern, filename)\n",
    "      name = filename[:-4]\n",
    "      if match:\n",
    "          well_number = int(match.group(1))  # Extract well number\n",
    "          patch_number = int(match.group(2)) # Extract patch number\n",
    "      else:\n",
    "          print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "      data_dict.append((name, well_number, patch_number, example.flatten()))\n",
    "\n",
    "  df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "  return df.sort_values(by=['well_number','patch_number'])\n",
    "\n",
    "def build_dataloaders_for_classiication(train_dataframe):\n",
    "    data = torch.from_numpy(np.vstack(train_dataframe['data'].to_numpy()))\n",
    "    data = torch.nan_to_num(data)\n",
    "    labels = torch.from_numpy(np.vstack(train_dataframe['well_number'].to_numpy())).squeeze() - 1\n",
    "\n",
    "    p = np.random.permutation(len(data))\n",
    "    with open('train_set_permutation.json', 'w') as f:\n",
    "        # Write permutation to file so that we can re-apply the same transform later\n",
    "        json.dump(p.tolist(), f)\n",
    "\n",
    "    data, labels = data[p], labels[p]\n",
    "    offset = int(len(data) * .5)\n",
    "    X_train, X_valid = data[:offset], data[offset:]\n",
    "    Y_train, Y_valid = labels[:offset], labels[offset:]\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = torch.tensor(scaler.transform(X_train)).float().reshape(-1, 1, 36, 36)\n",
    "    X_valid = torch.tensor(scaler.transform(X_valid)).float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "    examples_to_augment = X_train\n",
    "    labels_to_augment = Y_train\n",
    "\n",
    "    rolled_x, rolled_y = [], []\n",
    "    for i in range(1, 36):\n",
    "        rolled_x.append(torch.roll(examples_to_augment, i, dims=3))\n",
    "        rolled_y.append(labels_to_augment)\n",
    "\n",
    "    X_train, Y_train = torch.vstack((X_train, *rolled_x)), torch.hstack((Y_train, *rolled_y))\n",
    "\n",
    "    flipper = v2.RandomVerticalFlip(1)\n",
    "    X_train, Y_train = torch.vstack((X_train, flipper(examples_to_augment))), torch.hstack((Y_train, labels_to_augment))\n",
    "\n",
    "    train_dataset = WellsDataset(X_train, Y_train, None)\n",
    "    valid_dataset = WellsDataset(X_valid, Y_valid, None)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=128)\n",
    "\n",
    "    return train_dataloader, valid_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = build_dataloaders(build_dataframe())\n",
    "samples, labels = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Baseline Model\n",
    "\n",
    "- The CNN architecture consists of 5 layers without pooling.\n",
    "- A batch size of 128 was chosen to optimize computational efficiency during the training process.\n",
    "- The learning rate was set at 0.001 to guide the model through effective convergence.\n",
    "- Training was conducted over 30 epochs to capture the temporal evolution of features within the data.\n",
    "- Utilizing the Binary Cross Entropy loss function facilitated effective optimization, striking a balance between the dice coefficient and the binary cross-entropy components.\n",
    "- Data augmentation techniques, including flip and horizontal roll, were strategically incorporated to enhance the model's adaptability.\n",
    "- The optimizer used during training was the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    num_channels = 64\n",
    "    self.feature_extractor = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1, out_channels=num_channels, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=num_channels, out_channels=num_channels*2, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=num_channels*2, out_channels=num_channels*2, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=num_channels*2, out_channels=1, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  def forward(self, input):\n",
    "    x = self.feature_extractor(input)\n",
    "    return self.classifier(x)\n",
    "  \n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloaer, validation_dataloader, num_epochs, lr):\n",
    "  model = Baseline().to(DEVICE)\n",
    "  optimizer = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "  metric = BinaryJaccardIndex().to(DEVICE)\n",
    "  criterion = DiceLoss().to(DEVICE)\n",
    "  for e in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "    for input, labels in tqdm(iter(train_dataloaer)):\n",
    "      input = input.to(DEVICE)\n",
    "      labels = labels.to(DEVICE)\n",
    "      optimizer.zero_grad()\n",
    "      output = model(input)\n",
    "      loss = criterion(output, labels)\n",
    "      train_loss += loss.detach().item()\n",
    "      iou = metric(output, labels)\n",
    "      train_iou += iou.detach().item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_iou = 0\n",
    "    with torch.no_grad():\n",
    "      for input, labels in tqdm(iter(validation_dataloader)):\n",
    "        input = input.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        out = model(input)\n",
    "        loss = criterion(out, labels)\n",
    "        iou = metric(out, labels)\n",
    "        valid_loss += loss.detach().item()\n",
    "        valid_iou += iou.detach().item()\n",
    "    \n",
    "    print(f'Epoch: {e}')\n",
    "    print(f'Train loss:      {train_loss / len(train_dataloaer)}')\n",
    "    print(f'Validation loss: {valid_loss / len(validation_dataloader)}')\n",
    "    print(f'Train intersection over union:      {train_iou}')\n",
    "    print(f'Validation intersection over union: {valid_iou}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        # self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        # self.down4 = (Down(512, 1024 // factor))\n",
    "        # self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        # self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        # x4 = self.down3(x3)\n",
    "        # x5 = self.down4(x4)\n",
    "        # x = self.up1(x5, x4)\n",
    "        # x = self.up2(x, x3)\n",
    "        x = self.up3(x3, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    # def use_checkpointing(self):\n",
    "    #     self.inc = torch.utils.checkpoint(self.inc)\n",
    "    #     self.down1 = torch.utils.checkpoint(self.down1)\n",
    "    #     self.down2 = torch.utils.checkpoint(self.down2)\n",
    "    #     self.down3 = torch.utils.checkpoint(self.down3)\n",
    "    #     self.down4 = torch.utils.checkpoint(self.down4)\n",
    "    #     self.up1 = torch.utils.checkpoint(self.up1)\n",
    "    #     self.up2 = torch.utils.checkpoint(self.up2)\n",
    "    #     self.up3 = torch.utils.checkpoint(self.up3)\n",
    "    #     self.up4 = torch.utils.checkpoint(self.up4)\n",
    "    #     self.outc = torch.utils.checkpoint(self.outc)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=1, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand((128, 1,36,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([165888])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([165888])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(output, dim=1), dim=1).view(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wtf is up with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = build_dataframe()\n",
    "# data = torch.from_numpy(np.vstack(dataframe['data'].to_numpy()))\n",
    "# data = torch.nan_to_num(data)\n",
    "# labels = torch.from_numpy(np.vstack(dataframe['labels'].to_numpy())).reshape(-1, 1, 36, 36)\n",
    "\n",
    "# p = np.random.permutation(len(data))\n",
    "# data, labels = data[p], labels[p]\n",
    "\n",
    "# offset = int(len(data) * .8)\n",
    "# X_train, X_valid = data[:offset], data[offset:]\n",
    "# Y_train, Y_valid = labels[:offset].float(), labels[offset:].float()\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = torch.tensor(scaler.transform(X_train)).float().reshape(-1, 1, 36, 36)\n",
    "# X_valid = torch.tensor(scaler.transform(X_valid)).float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "# rolled_x, rolled_y = [], []\n",
    "# for i in range(1, 36, 2):\n",
    "#   rolled_x.append(torch.roll(X_train, i, dims=3))\n",
    "#   rolled_y.append(torch.roll(Y_train, i, dims=3))\n",
    "\n",
    "# X_train, Y_train = torch.vstack((X_train, *rolled_x)), torch.vstack((Y_train, *rolled_y))\n",
    "\n",
    "# flipper = v2.RandomVerticalFlip(1)\n",
    "# X_train, Y_train = torch.vstack((X_train, flipper(X_train))), torch.vstack((Y_train, flipper(Y_train)))\n",
    "\n",
    "# train_dataset = WellsDataset(X_train, Y_train, None)\n",
    "# valid_dataset = WellsDataset(X_valid, Y_valid, None)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './train/images/'\n",
    "data_dict = []\n",
    "pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "for i, filename in enumerate(os.listdir(data_dir)):\n",
    "    example = np.load(data_dir + filename)\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        well_number = int(match.group(1))  # Extract well number\n",
    "        patch_number = int(match.group(2)) # Extract patch number\n",
    "    else:\n",
    "        print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "    data_dict.append((filename, well_number, patch_number, example.flatten()))\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "\n",
    "df_y = pd.read_csv('train/y_train.csv')\n",
    "df_y['Unnamed: 0'] = df_y['Unnamed: 0'] + '.npy'\n",
    "\n",
    "# Create single dataframe with data and labels as lists\n",
    "merged = pd.merge(df, df_y, how='left', left_on='filename', right_on='Unnamed: 0')\n",
    "data_columns = [str(i) for i in range(1296)]\n",
    "labeled_data = merged[data_columns]\n",
    "# # Convert missing labels to all zeros\n",
    "labeled_data = np.nan_to_num(labeled_data.to_numpy())\n",
    "merged['labels'] = labeled_data.tolist()\n",
    "merged = merged.rename(columns={'Unnamed: 0':'label_name'})\n",
    "merged = merged.fillna(0.0)\n",
    "\n",
    "data = torch.from_numpy(np.vstack(merged['data'].to_numpy(dtype=np.ndarray)))\n",
    "# # Remove corruputed samples\n",
    "outliers = ((data.min(dim=1, keepdim=True).values == -999.2500) == True).flatten()\n",
    "\n",
    "merged = merged.drop(merged.loc[outliers.tolist()].index)\n",
    "merged = merged.sort_values(by=['well_number', 'patch_number']).reset_index().drop('index', axis=1)\n",
    "# # merged.to_csv(path_or_buf='./inputs/x_train_df.csv')\n",
    "# # return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>well_number</th>\n",
       "      <th>patch_number</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>well_1_patch_0.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0023756325, 0.0002592206, -0.00054234266, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>well_1_patch_1.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.00070917606, 0.0019150376, -0.0038494766, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>well_1_patch_2.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0023519993, -0.001029253, -0.0031194985, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>well_1_patch_3.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.0040180683, 0.002460301, -0.00080919266, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>well_1_patch_4.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.010236055, -0.012113214, 0.004949212, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>well_15_patch_198.npy</td>\n",
       "      <td>15</td>\n",
       "      <td>198</td>\n",
       "      <td>[-0.16682914, -0.06421369, -0.029622853, 0.186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>well_15_patch_199.npy</td>\n",
       "      <td>15</td>\n",
       "      <td>199</td>\n",
       "      <td>[-0.020118445, -0.010837793, -0.00872457, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>well_15_patch_200.npy</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>[-0.038962424, -0.029287964, -0.01792556, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>well_15_patch_201.npy</td>\n",
       "      <td>15</td>\n",
       "      <td>201</td>\n",
       "      <td>[-0.0042802095, -0.0018412471, -0.008901715, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>well_15_patch_202.npy</td>\n",
       "      <td>15</td>\n",
       "      <td>202</td>\n",
       "      <td>[-0.031695127, -0.00938797, -0.005555123, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9670 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  well_number  patch_number  \\\n",
       "7375     well_1_patch_0.npy            1             0   \n",
       "7813     well_1_patch_1.npy            1             1   \n",
       "8389     well_1_patch_2.npy            1             2   \n",
       "7975     well_1_patch_3.npy            1             3   \n",
       "9563     well_1_patch_4.npy            1             4   \n",
       "...                     ...          ...           ...   \n",
       "1757  well_15_patch_198.npy           15           198   \n",
       "1429  well_15_patch_199.npy           15           199   \n",
       "1020  well_15_patch_200.npy           15           200   \n",
       "909   well_15_patch_201.npy           15           201   \n",
       "275   well_15_patch_202.npy           15           202   \n",
       "\n",
       "                                                   data  \n",
       "7375  [-0.0023756325, 0.0002592206, -0.00054234266, ...  \n",
       "7813  [0.00070917606, 0.0019150376, -0.0038494766, 0...  \n",
       "8389  [-0.0023519993, -0.001029253, -0.0031194985, -...  \n",
       "7975  [-0.0040180683, 0.002460301, -0.00080919266, 0...  \n",
       "9563  [-0.010236055, -0.012113214, 0.004949212, 0.01...  \n",
       "...                                                 ...  \n",
       "1757  [-0.16682914, -0.06421369, -0.029622853, 0.186...  \n",
       "1429  [-0.020118445, -0.010837793, -0.00872457, -0.0...  \n",
       "1020  [-0.038962424, -0.029287964, -0.01792556, -0.0...  \n",
       "909   [-0.0042802095, -0.0018412471, -0.008901715, -...  \n",
       "275   [-0.031695127, -0.00938797, -0.005555123, -0.0...  \n",
       "\n",
       "[9670 rows x 4 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['well_number','patch_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1286</th>\n",
       "      <th>1287</th>\n",
       "      <th>1288</th>\n",
       "      <th>1289</th>\n",
       "      <th>1290</th>\n",
       "      <th>1291</th>\n",
       "      <th>1292</th>\n",
       "      <th>1293</th>\n",
       "      <th>1294</th>\n",
       "      <th>1295</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well_0_patch_0.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well_0_patch_1.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well_0_patch_10.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>well_0_patch_100.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well_0_patch_101.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>well_15_patch_95.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10286</th>\n",
       "      <td>well_15_patch_96.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10287</th>\n",
       "      <td>well_15_patch_97.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10288</th>\n",
       "      <td>well_15_patch_98.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>well_15_patch_99.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10290 rows × 1297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0  0  1  2  3  4  5  6  7  8  ...  1286  1287  1288  \\\n",
       "0        well_0_patch_0.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "1        well_0_patch_1.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "2       well_0_patch_10.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "3      well_0_patch_100.npy  0  0  0  0  0  0  0  0  0  ...     1     0     0   \n",
       "4      well_0_patch_101.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "...                     ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   \n",
       "10285  well_15_patch_95.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "10286  well_15_patch_96.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "10287  well_15_patch_97.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "10288  well_15_patch_98.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "10289  well_15_patch_99.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "\n",
       "       1289  1290  1291  1292  1293  1294  1295  \n",
       "0         0     0     0     0     0     0     0  \n",
       "1         0     0     0     0     0     0     0  \n",
       "2         0     0     0     0     0     0     0  \n",
       "3         0     0     0     0     0     0     0  \n",
       "4         0     0     0     0     0     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...  \n",
       "10285     0     0     0     0     0     0     0  \n",
       "10286     0     0     0     0     0     0     0  \n",
       "10287     0     0     0     0     0     0     0  \n",
       "10288     0     0     0     0     0     0     0  \n",
       "10289     0     0     0     0     0     0     0  \n",
       "\n",
       "[10290 rows x 1297 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_y) - len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1286</th>\n",
       "      <th>1287</th>\n",
       "      <th>1288</th>\n",
       "      <th>1289</th>\n",
       "      <th>1290</th>\n",
       "      <th>1291</th>\n",
       "      <th>1292</th>\n",
       "      <th>1293</th>\n",
       "      <th>1294</th>\n",
       "      <th>1295</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well_0_patch_0.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well_0_patch_1.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well_0_patch_10.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>well_0_patch_100.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well_0_patch_101.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>well_0_patch_95.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>well_0_patch_96.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>well_0_patch_97.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>well_0_patch_98.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>well_0_patch_99.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 1297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0  0  1  2  3  4  5  6  7  8  ...  1286  1287  1288  \\\n",
       "0      well_0_patch_0.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "1      well_0_patch_1.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "2     well_0_patch_10.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "3    well_0_patch_100.npy  0  0  0  0  0  0  0  0  0  ...     1     0     0   \n",
       "4    well_0_patch_101.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "..                    ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   \n",
       "161   well_0_patch_95.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "162   well_0_patch_96.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "163   well_0_patch_97.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "164   well_0_patch_98.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "165   well_0_patch_99.npy  0  0  0  0  0  0  0  0  0  ...     0     0     0   \n",
       "\n",
       "     1289  1290  1291  1292  1293  1294  1295  \n",
       "0       0     0     0     0     0     0     0  \n",
       "1       0     0     0     0     0     0     0  \n",
       "2       0     0     0     0     0     0     0  \n",
       "3       0     0     0     0     0     0     0  \n",
       "4       0     0     0     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...  \n",
       "161     0     0     0     0     0     0     0  \n",
       "162     0     0     0     0     0     0     0  \n",
       "163     0     0     0     0     0     0     0  \n",
       "164     0     0     0     0     0     0     0  \n",
       "165     0     0     0     0     0     0     0  \n",
       "\n",
       "[166 rows x 1297 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y[df_y['Unnamed: 0'].str.extract(pattern)[0] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03169513, -0.00938797, -0.00555512, ..., -0.02175638,\n",
       "        -0.0443297 , -0.06808725],\n",
       "       [-0.03807807, -0.05087709, -0.04050902, ..., -0.02837628,\n",
       "         0.2898331 , -0.03786528],\n",
       "       [-0.01640931, -0.02287549, -0.00776434, ..., -0.03069016,\n",
       "        -0.00802898,  0.01437011],\n",
       "       ...,\n",
       "       [        nan,  0.04923961,         nan, ...,         nan,\n",
       "         0.04923961,  0.04923961],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"train/images/well_15_patch_202.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.03169513, -0.00938797, -0.00555512,  ..., -0.02175638,\n",
       "         -0.04432970, -0.06808725],\n",
       "        [-0.03807807, -0.05087709, -0.04050902,  ..., -0.02837628,\n",
       "          0.28983310, -0.03786528],\n",
       "        [-0.01640931, -0.02287549, -0.00776434,  ..., -0.03069016,\n",
       "         -0.00802898,  0.01437011],\n",
       "        ...,\n",
       "        [        nan,  0.04923961,         nan,  ...,         nan,\n",
       "          0.04923961,  0.04923961],\n",
       "        [        nan,         nan,         nan,  ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan,  ...,         nan,\n",
       "                 nan,         nan]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.load(\"train/images/well_15_patch_202.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.03169513, -0.00938797, -0.00555512,  ..., -0.02175638,\n",
       "         -0.04432970, -0.06808725],\n",
       "        [-0.03807807, -0.05087709, -0.04050902,  ..., -0.02837628,\n",
       "          0.28983310, -0.03786528],\n",
       "        [-0.01640931, -0.02287549, -0.00776434,  ..., -0.03069016,\n",
       "         -0.00802898,  0.01437011],\n",
       "        ...,\n",
       "        [        nan,  0.04923961,         nan,  ...,         nan,\n",
       "          0.04923961,  0.04923961],\n",
       "        [        nan,         nan,         nan,  ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan,  ...,         nan,\n",
       "                 nan,         nan]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.vstack(df[df['filename'] == \"well_15_patch_202.npy\"]['data'].to_numpy())).reshape(36, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9435, 1296)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.vstack(merged['labels'].to_numpy(dtype=np.ndarray))*1.\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9435,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_non_zero_per_row = np.count_nonzero(labels, axis=1)\n",
    "num_non_zero_per_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2012, 1296)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[num_non_zero_per_row < 25].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAkACQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiv//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACQAAAAkCAAAAADEa8dEAAAAGElEQVR4AWNgGAWjITAaAqMhMBoCxIYAAAU0AAFCwR6cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=36x36>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VF.to_pil_image(torch.from_numpy(labels[num_non_zero_per_row < 25][1050].reshape(36, 36)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(num_non_zero_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2541, 2183, 3464,  999,  204,   32,    7,    2,    2,    1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0. ,  53.7, 107.4, 161.1, 214.8, 268.5, 322.2, 375.9, 429.6,\n",
       "       483.3, 537. ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.541e+03, 2.183e+03, 3.464e+03, 9.990e+02, 2.040e+02, 3.200e+01,\n",
       "        7.000e+00, 2.000e+00, 2.000e+00, 1.000e+00]),\n",
       " array([  0. ,  53.7, 107.4, 161.1, 214.8, 268.5, 322.2, 375.9, 429.6,\n",
       "        483.3, 537. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAApZUlEQVR4nO3df2xVdZ7/8de1v6y1PUMpvbd3qbW7IgtTINkyW27XyO8CoXYUszDDpoEMCzrywwaIApONuJlQdDKga1eWdQ0I4tQ/pA4J2KEGqUOg/Kg2FgTCRHDK0kvRbW9bpt5i/Xz/mHC+XorILcX2U56P5Cbcc949nPOJMzxz7o96jDFGAAAAlrmrr08AAACgJ4gYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFaK7esTuF2++eYbXbhwQcnJyfJ4PH19OgAA4CYYY9TW1ia/36+77rrxvZYBGzEXLlxQZmZmX58GAADogYaGBg0dOvSGMwM2YpKTkyX9dRFSUlL6+GwAAMDNaG1tVWZmpvvv+I0M2Ii5+hJSSkoKEQMAgGVu5q0gvLEXAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFaKKmI2bdqk0aNHux9bDgQCeu+999z98+fPl8fjiXiMGzcu4hjhcFhLly5VWlqakpKSVFRUpPPnz0fMNDc3q7i4WI7jyHEcFRcXq6WlpedXCQAABpyoImbo0KFav369jh07pmPHjmnSpEn66U9/qhMnTrgz06dPV2Njo/vYs2dPxDFKSkpUUVGh8vJyHThwQO3t7SosLFRXV5c7M3fuXNXV1amyslKVlZWqq6tTcXHxLV4qAAAYSDzGGHMrB0hNTdVvfvMbLViwQPPnz1dLS4vefffd686GQiENGTJE27dv15w5cyT9/18PsGfPHk2bNk0nT57UyJEjVVNTo7y8PElSTU2NAoGATp06peHDh9/UebW2tspxHIVCIb7sDgAAS0Tz73eP3xPT1dWl8vJyXb58WYFAwN2+f/9+paen68EHH9TChQvV1NTk7qutrdWVK1dUUFDgbvP7/crJydHBgwclSYcOHZLjOG7ASNK4cePkOI47AwAAEPWvHaivr1cgENBXX32le++9VxUVFRo5cqQkacaMGfrnf/5nZWVl6ezZs/q3f/s3TZo0SbW1tUpISFAwGFR8fLwGDRoUcUyv16tgMChJCgaDSk9P7/b3pqenuzPXEw6HFQ6H3eetra3RXhoAALBI1BEzfPhw1dXVqaWlRe+8847mzZun6upqjRw50n2JSJJycnI0duxYZWVlaffu3Zo1a9Z3HtMYE/E7Eq73+xKunblWaWmpnn/++WgvBwAAWCrql5Pi4+P1wAMPaOzYsSotLdWYMWP08ssvX3c2IyNDWVlZOnPmjCTJ5/Ops7NTzc3NEXNNTU3yer3uzMWLF7sd69KlS+7M9axevVqhUMh9NDQ0RHtpAADAIrf8PTHGmIiXcb7tyy+/VENDgzIyMiRJubm5iouLU1VVlTvT2Nio48ePKz8/X5IUCAQUCoV05MgRd+bw4cMKhULuzPUkJCS4H/3mN1cDADDwRfVy0po1azRjxgxlZmaqra1N5eXl2r9/vyorK9Xe3q61a9fq8ccfV0ZGhs6dO6c1a9YoLS1Njz32mCTJcRwtWLBAK1as0ODBg5WamqqVK1dq1KhRmjJliiRpxIgRmj59uhYuXKjNmzdLkhYtWqTCwsKb/mQSBo77V+3u61OI2rn1M/v6FADgjhBVxFy8eFHFxcVqbGyU4zgaPXq0KisrNXXqVHV0dKi+vl7btm1TS0uLMjIyNHHiRL399ttKTk52j7Fx40bFxsZq9uzZ6ujo0OTJk7V161bFxMS4Mzt27NCyZcvcTzEVFRWprKysly4ZAAAMBLf8PTH9Fd8TMzBwJwYA7iw/yPfEAAAA9CUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlaKKmE2bNmn06NFKSUlRSkqKAoGA3nvvPXe/MUZr166V3+9XYmKiJkyYoBMnTkQcIxwOa+nSpUpLS1NSUpKKiop0/vz5iJnm5mYVFxfLcRw5jqPi4mK1tLT0/CoBAMCAE1XEDB06VOvXr9exY8d07NgxTZo0ST/96U/dUHnxxRe1YcMGlZWV6ejRo/L5fJo6dara2trcY5SUlKiiokLl5eU6cOCA2tvbVVhYqK6uLndm7ty5qqurU2VlpSorK1VXV6fi4uJeumQAADAQeIwx5lYOkJqaqt/85jf6xS9+Ib/fr5KSEj377LOS/nrXxev16oUXXtATTzyhUCikIUOGaPv27ZozZ44k6cKFC8rMzNSePXs0bdo0nTx5UiNHjlRNTY3y8vIkSTU1NQoEAjp16pSGDx9+U+fV2toqx3EUCoWUkpJyK5eIPnT/qt19fQpRO7d+Zl+fAgBYK5p/v3v8npiuri6Vl5fr8uXLCgQCOnv2rILBoAoKCtyZhIQEjR8/XgcPHpQk1dbW6sqVKxEzfr9fOTk57syhQ4fkOI4bMJI0btw4OY7jzlxPOBxWa2trxAMAAAxcUUdMfX297r33XiUkJOjJJ59URUWFRo4cqWAwKEnyer0R816v190XDAYVHx+vQYMG3XAmPT2929+bnp7uzlxPaWmp+x4ax3GUmZkZ7aUBAACLRB0xw4cPV11dnWpqavTLX/5S8+bN06effuru93g8EfPGmG7brnXtzPXmv+84q1evVigUch8NDQ03e0kAAMBCUUdMfHy8HnjgAY0dO1alpaUaM2aMXn75Zfl8PknqdrekqanJvTvj8/nU2dmp5ubmG85cvHix29976dKlbnd5vi0hIcH91NTVBwAAGLhu+XtijDEKh8PKzs6Wz+dTVVWVu6+zs1PV1dXKz8+XJOXm5iouLi5iprGxUcePH3dnAoGAQqGQjhw54s4cPnxYoVDInQEAAIiNZnjNmjWaMWOGMjMz1dbWpvLycu3fv1+VlZXyeDwqKSnRunXrNGzYMA0bNkzr1q3TPffco7lz50qSHMfRggULtGLFCg0ePFipqalauXKlRo0apSlTpkiSRowYoenTp2vhwoXavHmzJGnRokUqLCy86U8mAQCAgS+qiLl48aKKi4vV2Ngox3E0evRoVVZWaurUqZKkZ555Rh0dHXrqqafU3NysvLw87d27V8nJye4xNm7cqNjYWM2ePVsdHR2aPHmytm7dqpiYGHdmx44dWrZsmfsppqKiIpWVlfXG9QIAgAHilr8npr/ie2IGBr4nBgDuLD/I98QAAAD0JSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICVYqMZLi0t1c6dO3Xq1CklJiYqPz9fL7zwgoYPH+7OzJ8/X2+88UbEz+Xl5ammpsZ9Hg6HtXLlSv3ud79TR0eHJk+erFdffVVDhw51Z5qbm7Vs2TLt2rVLklRUVKRXXnlFP/rRj3pynb3u/lW7+/oUonZu/cy+PgUAAHpNVHdiqqurtXjxYtXU1Kiqqkpff/21CgoKdPny5Yi56dOnq7Gx0X3s2bMnYn9JSYkqKipUXl6uAwcOqL29XYWFherq6nJn5s6dq7q6OlVWVqqyslJ1dXUqLi6+hUsFAAADSVR3YiorKyOeb9myRenp6aqtrdXDDz/sbk9ISJDP57vuMUKhkF5//XVt375dU6ZMkSS9+eabyszM1Pvvv69p06bp5MmTqqysVE1NjfLy8iRJr732mgKBgE6fPh1x5wcAANyZbuk9MaFQSJKUmpoasX3//v1KT0/Xgw8+qIULF6qpqcndV1tbqytXrqigoMDd5vf7lZOTo4MHD0qSDh06JMdx3ICRpHHjxslxHHfmWuFwWK2trREPAAAwcPU4YowxWr58uR566CHl5OS422fMmKEdO3Zo3759+u1vf6ujR49q0qRJCofDkqRgMKj4+HgNGjQo4nher1fBYNCdSU9P7/Z3pqenuzPXKi0tleM47iMzM7OnlwYAACwQ1ctJ37ZkyRJ98sknOnDgQMT2OXPmuH/OycnR2LFjlZWVpd27d2vWrFnfeTxjjDwej/v823/+rplvW716tZYvX+4+b21tJWQAABjAenQnZunSpdq1a5c++OCDiE8UXU9GRoaysrJ05swZSZLP51NnZ6eam5sj5pqamuT1et2ZixcvdjvWpUuX3JlrJSQkKCUlJeIBAAAGrqgixhijJUuWaOfOndq3b5+ys7O/92e+/PJLNTQ0KCMjQ5KUm5uruLg4VVVVuTONjY06fvy48vPzJUmBQEChUEhHjhxxZw4fPqxQKOTOAACAO1tULyctXrxYb731ln7/+98rOTnZfX+K4zhKTExUe3u71q5dq8cff1wZGRk6d+6c1qxZo7S0ND322GPu7IIFC7RixQoNHjxYqampWrlypUaNGuV+WmnEiBGaPn26Fi5cqM2bN0uSFi1apMLCQj6ZBAAAJEUZMZs2bZIkTZgwIWL7li1bNH/+fMXExKi+vl7btm1TS0uLMjIyNHHiRL399ttKTk525zdu3KjY2FjNnj3b/bK7rVu3KiYmxp3ZsWOHli1b5n6KqaioSGVlZT29TgAAMMBEFTHGmBvuT0xM1B/+8IfvPc7dd9+tV155Ra+88sp3zqSmpurNN9+M5vQAAMAdhN+dBAAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArBTb1yeAH879q3b39SkAANBruBMDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArRRUxpaWl+slPfqLk5GSlp6fr0Ucf1enTpyNmjDFau3at/H6/EhMTNWHCBJ04cSJiJhwOa+nSpUpLS1NSUpKKiop0/vz5iJnm5mYVFxfLcRw5jqPi4mK1tLT07CoBAMCAE1XEVFdXa/HixaqpqVFVVZW+/vprFRQU6PLly+7Miy++qA0bNqisrExHjx6Vz+fT1KlT1dbW5s6UlJSooqJC5eXlOnDggNrb21VYWKiuri53Zu7cuaqrq1NlZaUqKytVV1en4uLiXrhkAAAwEHiMMaanP3zp0iWlp6erurpaDz/8sIwx8vv9Kikp0bPPPivpr3ddvF6vXnjhBT3xxBMKhUIaMmSItm/frjlz5kiSLly4oMzMTO3Zs0fTpk3TyZMnNXLkSNXU1CgvL0+SVFNTo0AgoFOnTmn48OHfe26tra1yHEehUEgpKSk9vcTvdP+q3b1+TAwM59bP7OtTAABrRfPv9y29JyYUCkmSUlNTJUlnz55VMBhUQUGBO5OQkKDx48fr4MGDkqTa2lpduXIlYsbv9ysnJ8edOXTokBzHcQNGksaNGyfHcdyZa4XDYbW2tkY8AADAwNXjiDHGaPny5XrooYeUk5MjSQoGg5Ikr9cbMev1et19wWBQ8fHxGjRo0A1n0tPTu/2d6enp7sy1SktL3ffPOI6jzMzMnl4aAACwQI8jZsmSJfrkk0/0u9/9rts+j8cT8dwY023bta6dud78jY6zevVqhUIh99HQ0HAzlwEAACzVo4hZunSpdu3apQ8++EBDhw51t/t8PknqdrekqanJvTvj8/nU2dmp5ubmG85cvHix29976dKlbnd5rkpISFBKSkrEAwAADFxRRYwxRkuWLNHOnTu1b98+ZWdnR+zPzs6Wz+dTVVWVu62zs1PV1dXKz8+XJOXm5iouLi5iprGxUcePH3dnAoGAQqGQjhw54s4cPnxYoVDInQEAAHe22GiGFy9erLfeeku///3vlZyc7N5xcRxHiYmJ8ng8Kikp0bp16zRs2DANGzZM69at0z333KO5c+e6swsWLNCKFSs0ePBgpaamauXKlRo1apSmTJkiSRoxYoSmT5+uhQsXavPmzZKkRYsWqbCw8KY+mQQAAAa+qCJm06ZNkqQJEyZEbN+yZYvmz58vSXrmmWfU0dGhp556Ss3NzcrLy9PevXuVnJzszm/cuFGxsbGaPXu2Ojo6NHnyZG3dulUxMTHuzI4dO7Rs2TL3U0xFRUUqKyvryTUCAIAB6Ja+J6Y/43ti0Ff4nhgA6Lkf7HtiAAAA+goRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASlFHzIcffqhHHnlEfr9fHo9H7777bsT++fPny+PxRDzGjRsXMRMOh7V06VKlpaUpKSlJRUVFOn/+fMRMc3OziouL5TiOHMdRcXGxWlpaor5AAAAwMEUdMZcvX9aYMWNUVlb2nTPTp09XY2Oj+9izZ0/E/pKSElVUVKi8vFwHDhxQe3u7CgsL1dXV5c7MnTtXdXV1qqysVGVlperq6lRcXBzt6QIAgAEqNtofmDFjhmbMmHHDmYSEBPl8vuvuC4VCev3117V9+3ZNmTJFkvTmm28qMzNT77//vqZNm6aTJ0+qsrJSNTU1ysvLkyS99tprCgQCOn36tIYPHx7taQMAgAHmtrwnZv/+/UpPT9eDDz6ohQsXqqmpyd1XW1urK1euqKCgwN3m9/uVk5OjgwcPSpIOHTokx3HcgJGkcePGyXEcd+Za4XBYra2tEQ8AADBw9XrEzJgxQzt27NC+ffv029/+VkePHtWkSZMUDoclScFgUPHx8Ro0aFDEz3m9XgWDQXcmPT2927HT09PdmWuVlpa6759xHEeZmZm9fGUAAKA/ifrlpO8zZ84c9885OTkaO3assrKytHv3bs2aNes7f84YI4/H4z7/9p+/a+bbVq9ereXLl7vPW1tbCRkAAAaw2/4R64yMDGVlZenMmTOSJJ/Pp87OTjU3N0fMNTU1yev1ujMXL17sdqxLly65M9dKSEhQSkpKxAMAAAxctz1ivvzySzU0NCgjI0OSlJubq7i4OFVVVbkzjY2NOn78uPLz8yVJgUBAoVBIR44ccWcOHz6sUCjkzgAAgDtb1C8ntbe3609/+pP7/OzZs6qrq1NqaqpSU1O1du1aPf7448rIyNC5c+e0Zs0apaWl6bHHHpMkOY6jBQsWaMWKFRo8eLBSU1O1cuVKjRo1yv200ogRIzR9+nQtXLhQmzdvliQtWrRIhYWFfDIJAABI6kHEHDt2TBMnTnSfX30fyrx587Rp0ybV19dr27ZtamlpUUZGhiZOnKi3335bycnJ7s9s3LhRsbGxmj17tjo6OjR58mRt3bpVMTEx7syOHTu0bNky91NMRUVFN/xuGgAAcGfxGGNMX5/E7dDa2irHcRQKhW7L+2PuX7W714+JgeHc+pl9fQoAYK1o/v3mdycBAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALBS1BHz4Ycf6pFHHpHf75fH49G7774bsd8Yo7Vr18rv9ysxMVETJkzQiRMnImbC4bCWLl2qtLQ0JSUlqaioSOfPn4+YaW5uVnFxsRzHkeM4Ki4uVktLS9QXCAAABqaoI+by5csaM2aMysrKrrv/xRdf1IYNG1RWVqajR4/K5/Np6tSpamtrc2dKSkpUUVGh8vJyHThwQO3t7SosLFRXV5c7M3fuXNXV1amyslKVlZWqq6tTcXFxDy4RAAAMRB5jjOnxD3s8qqio0KOPPirpr3dh/H6/SkpK9Oyzz0r6610Xr9erF154QU888YRCoZCGDBmi7du3a86cOZKkCxcuKDMzU3v27NG0adN08uRJjRw5UjU1NcrLy5Mk1dTUKBAI6NSpUxo+fPj3nltra6scx1EoFFJKSkpPL/E73b9qd68fEwPDufUz+/oUAMBa0fz73avviTl79qyCwaAKCgrcbQkJCRo/frwOHjwoSaqtrdWVK1ciZvx+v3JyctyZQ4cOyXEcN2Akady4cXIcx50BAAB3ttjePFgwGJQkeb3eiO1er1eff/65OxMfH69BgwZ1m7n688FgUOnp6d2On56e7s5cKxwOKxwOu89bW1t7fiEAAKDf69WIucrj8UQ8N8Z023ata2euN3+j45SWlur555/vwdkCvcvGlxp5CQyAjXr15SSfzydJ3e6WNDU1uXdnfD6fOjs71dzcfMOZixcvdjv+pUuXut3luWr16tUKhULuo6Gh4ZavBwAA9F+9GjHZ2dny+Xyqqqpyt3V2dqq6ulr5+fmSpNzcXMXFxUXMNDY26vjx4+5MIBBQKBTSkSNH3JnDhw8rFAq5M9dKSEhQSkpKxAMAAAxcUb+c1N7erj/96U/u87Nnz6qurk6pqam67777VFJSonXr1mnYsGEaNmyY1q1bp3vuuUdz586VJDmOowULFmjFihUaPHiwUlNTtXLlSo0aNUpTpkyRJI0YMULTp0/XwoULtXnzZknSokWLVFhYeFOfTAIAAANf1BFz7NgxTZw40X2+fPlySdK8efO0detWPfPMM+ro6NBTTz2l5uZm5eXlae/evUpOTnZ/ZuPGjYqNjdXs2bPV0dGhyZMna+vWrYqJiXFnduzYoWXLlrmfYioqKvrO76YBAAB3nlv6npj+jO+JAW4eb+wF0F/02ffEAAAA/FCIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAVur1iFm7dq08Hk/Ew+fzufuNMVq7dq38fr8SExM1YcIEnThxIuIY4XBYS5cuVVpampKSklRUVKTz58/39qkCAACL3ZY7MT/+8Y/V2NjoPurr6919L774ojZs2KCysjIdPXpUPp9PU6dOVVtbmztTUlKiiooKlZeX68CBA2pvb1dhYaG6urpux+kCAAALxd6Wg8bGRtx9ucoYo5deekm/+tWvNGvWLEnSG2+8Ia/Xq7feektPPPGEQqGQXn/9dW3fvl1TpkyRJL355pvKzMzU+++/r2nTpt2OUwYAAJa5LXdizpw5I7/fr+zsbP3sZz/TZ599Jkk6e/asgsGgCgoK3NmEhASNHz9eBw8elCTV1tbqypUrETN+v185OTnuzPWEw2G1trZGPAAAwMDV6xGTl5enbdu26Q9/+INee+01BYNB5efn68svv1QwGJQkeb3eiJ/xer3uvmAwqPj4eA0aNOg7Z66ntLRUjuO4j8zMzF6+MgAA0J/0esTMmDFDjz/+uEaNGqUpU6Zo9+7dkv76stFVHo8n4meMMd22Xev7ZlavXq1QKOQ+GhoabuEqAABAf3fbP2KdlJSkUaNG6cyZM+77ZK69o9LU1OTenfH5fOrs7FRzc/N3zlxPQkKCUlJSIh4AAGDguu0REw6HdfLkSWVkZCg7O1s+n09VVVXu/s7OTlVXVys/P1+SlJubq7i4uIiZxsZGHT9+3J0BAADo9U8nrVy5Uo888ojuu+8+NTU16de//rVaW1s1b948eTwelZSUaN26dRo2bJiGDRumdevW6Z577tHcuXMlSY7jaMGCBVqxYoUGDx6s1NRUrVy50n15CgAAQLoNEXP+/Hn9/Oc/1xdffKEhQ4Zo3LhxqqmpUVZWliTpmWeeUUdHh5566ik1NzcrLy9Pe/fuVXJysnuMjRs3KjY2VrNnz1ZHR4cmT56srVu3KiYmprdPFwAAWMpjjDF9fRK3Q2trqxzHUSgUui3vj7l/1e5ePybQV86tn9nXpwAAkqL795vfnQQAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALBSbF+fAIC+d/+q3X19ClE7t35mX58CgD7GnRgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFbq9xHz6quvKjs7W3fffbdyc3P1xz/+sa9PCQAA9AOxfX0CN/L222+rpKREr776qv7pn/5Jmzdv1owZM/Tpp5/qvvvu6+vTA9CH7l+1u69PIWrn1s/s61MABpR+fSdmw4YNWrBggf71X/9VI0aM0EsvvaTMzExt2rSpr08NAAD0sX57J6azs1O1tbVatWpVxPaCggIdPHiw23w4HFY4HHafh0IhSVJra+ttOb9vwn+5LccFMHDdrv8/AgaSq/87McZ872y/jZgvvvhCXV1d8nq9Edu9Xq+CwWC3+dLSUj3//PPdtmdmZt62cwSAaDgv9fUZAPZoa2uT4zg3nOm3EXOVx+OJeG6M6bZNklavXq3ly5e7z7/55hv93//9nwYPHnzd+VvR2tqqzMxMNTQ0KCUlpVePfSdiPXsX69m7WM/exXr2roG4nsYYtbW1ye/3f+9sv42YtLQ0xcTEdLvr0tTU1O3ujCQlJCQoISEhYtuPfvSj23mKSklJGTD/0fQHrGfvYj17F+vZu1jP3jXQ1vP77sBc1W/f2BsfH6/c3FxVVVVFbK+qqlJ+fn4fnRUAAOgv+u2dGElavny5iouLNXbsWAUCAf33f/+3/vznP+vJJ5/s61MDAAB9rF9HzJw5c/Tll1/q3//939XY2KicnBzt2bNHWVlZfXpeCQkJeu6557q9fIWeYT17F+vZu1jP3sV69q47fT095mY+wwQAANDP9Nv3xAAAANwIEQMAAKxExAAAACsRMQAAwEpETJReffVVZWdn6+6771Zubq7++Mc/9vUp9UsffvihHnnkEfn9fnk8Hr377rsR+40xWrt2rfx+vxITEzVhwgSdOHEiYiYcDmvp0qVKS0tTUlKSioqKdP78+R/wKvqH0tJS/eQnP1FycrLS09P16KOP6vTp0xEzrOfN27Rpk0aPHu1+OVggENB7773n7mctb01paak8Ho9KSkrcbazpzVu7dq08Hk/Ew+fzuftZy2sY3LTy8nITFxdnXnvtNfPpp5+ap59+2iQlJZnPP/+8r0+t39mzZ4/51a9+Zd555x0jyVRUVETsX79+vUlOTjbvvPOOqa+vN3PmzDEZGRmmtbXVnXnyySfN3/zN35iqqirz0UcfmYkTJ5oxY8aYr7/++ge+mr41bdo0s2XLFnP8+HFTV1dnZs6cae677z7T3t7uzrCeN2/Xrl1m9+7d5vTp0+b06dNmzZo1Ji4uzhw/ftwYw1reiiNHjpj777/fjB492jz99NPudtb05j333HPmxz/+sWlsbHQfTU1N7n7WMhIRE4V//Md/NE8++WTEtr//+783q1at6qMzssO1EfPNN98Yn89n1q9f72776quvjOM45r/+67+MMca0tLSYuLg4U15e7s787//+r7nrrrtMZWXlD3bu/VFTU5ORZKqrq40xrGdvGDRokPmf//kf1vIWtLW1mWHDhpmqqiozfvx4N2JY0+g899xzZsyYMdfdx1p2x8tJN6mzs1O1tbUqKCiI2F5QUKCDBw/20VnZ6ezZswoGgxFrmZCQoPHjx7trWVtbqytXrkTM+P1+5eTk3PHrHQqFJEmpqamSWM9b0dXVpfLycl2+fFmBQIC1vAWLFy/WzJkzNWXKlIjtrGn0zpw5I7/fr+zsbP3sZz/TZ599Jom1vJ5+/Y29/ckXX3yhrq6ubr980uv1dvsllbixq+t1vbX8/PPP3Zn4+HgNGjSo28ydvN7GGC1fvlwPPfSQcnJyJLGePVFfX69AIKCvvvpK9957ryoqKjRy5Ej3/+RZy+iUl5fro48+0tGjR7vt47/P6OTl5Wnbtm168MEHdfHiRf36179Wfn6+Tpw4wVpeBxETJY/HE/HcGNNtG25OT9byTl/vJUuW6JNPPtGBAwe67WM9b97w4cNVV1enlpYWvfPOO5o3b56qq6vd/azlzWtoaNDTTz+tvXv36u677/7OOdb05syYMcP986hRoxQIBPR3f/d3euONNzRu3DhJrOW38XLSTUpLS1NMTEy3km1qaupWxbixq++0v9Fa+nw+dXZ2qrm5+Ttn7jRLly7Vrl279MEHH2jo0KHudtYzevHx8XrggQc0duxYlZaWasyYMXr55ZdZyx6ora1VU1OTcnNzFRsbq9jYWFVXV+s//uM/FBsb664Ja9ozSUlJGjVqlM6cOcN/n9dBxNyk+Ph45ebmqqqqKmJ7VVWV8vPz++is7JSdnS2fzxexlp2dnaqurnbXMjc3V3FxcREzjY2NOn78+B233sYYLVmyRDt37tS+ffuUnZ0dsZ/1vHXGGIXDYdayByZPnqz6+nrV1dW5j7Fjx+pf/uVfVFdXp7/9279lTW9BOBzWyZMnlZGRwX+f19MX7ya21dWPWL/++uvm008/NSUlJSYpKcmcO3eur0+t32lrazMff/yx+fjjj40ks2HDBvPxxx+7H0dfv369cRzH7Ny509TX15uf//zn1/2Y4NChQ837779vPvroIzNp0qQB+zHBG/nlL39pHMcx+/fvj/jY5V/+8hd3hvW8eatXrzYffvihOXv2rPnkk0/MmjVrzF133WX27t1rjGEte8O3P51kDGsajRUrVpj9+/ebzz77zNTU1JjCwkKTnJzs/jvDWkYiYqL0n//5nyYrK8vEx8ebf/iHf3A/5opIH3zwgZHU7TFv3jxjzF8/Kvjcc88Zn89nEhISzMMPP2zq6+sjjtHR0WGWLFliUlNTTWJioiksLDR//vOf++Bq+tb11lGS2bJlizvDet68X/ziF+7/hocMGWImT57sBowxrGVvuDZiWNObd/V7X+Li4ozf7zezZs0yJ06ccPezlpE8xhjTN/eAAAAAeo73xAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKz0/wArnnTHyeGK2AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=num_non_zero_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(np.vstack(merged['data'].to_numpy()))\n",
    "labels = torch.from_numpy(np.vstack(merged['labels'].to_numpy()))\n",
    "\n",
    "p = np.random.permutation(len(data))\n",
    "data, labels = data[p], labels[p]\n",
    "\n",
    "offset = int(len(data) * .8)\n",
    "X_train, X_valid = data[:offset], data[offset:]\n",
    "Y_train, Y_valid = labels[:offset].float().reshape(-1, 1, 36, 36), labels[offset:].float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = torch.tensor(scaler.transform(X_train)).float().reshape(-1, 1, 36, 36)\n",
    "X_valid = torch.tensor(scaler.transform(X_valid)).float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "num_non_zero_y = torch.count_nonzero(labels[:offset], axis=1)\n",
    "examples_to_augment = X_train[num_non_zero_y > 25]\n",
    "labels_to_augment = Y_train[num_non_zero_y > 25]\n",
    "\n",
    "rolled_x, rolled_y = [], []\n",
    "for i in range(1, 36):\n",
    "  rolled_x.append(torch.roll(examples_to_augment, i, dims=3))\n",
    "  rolled_y.append(torch.roll(labels_to_augment, i, dims=3))\n",
    "\n",
    "X_train, Y_train = torch.vstack((X_train, *rolled_x)), torch.vstack((Y_train, *rolled_y))\n",
    "\n",
    "flipper = v2.RandomVerticalFlip(1)\n",
    "X_train, Y_train = torch.vstack((X_train, flipper(examples_to_augment))), torch.vstack((Y_train, flipper(labels_to_augment)))\n",
    "\n",
    "train_dataset = WellsDataset(X_train, Y_train, None)\n",
    "valid_dataset = WellsDataset(X_valid, Y_valid, None)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_dataframe():\n",
    "  data_dir = './test/images/'\n",
    "  data_dict = []\n",
    "  pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "  for i, filename in enumerate(os.listdir(data_dir)):\n",
    "      example = np.load(data_dir + filename)\n",
    "      match = re.match(pattern, filename)\n",
    "      name = filename[:-4]\n",
    "      if match:\n",
    "          well_number = int(match.group(1))  # Extract well number\n",
    "          patch_number = int(match.group(2)) # Extract patch number\n",
    "      else:\n",
    "          print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "      data_dict.append((name, well_number, patch_number, example.flatten()))\n",
    "\n",
    "  df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "  return df.sort_values(by=['well_number','patch_number'])\n",
    "\n",
    "def build_dataframe():\n",
    "    data_dir = './train/images/'\n",
    "    data_dict = []\n",
    "    pattern = r'well_(\\d+)_patch_(\\d+)\\.npy'\n",
    "    for i, filename in enumerate(os.listdir(data_dir)):\n",
    "        example = np.load(data_dir + filename)\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            well_number = int(match.group(1))  # Extract well number\n",
    "            patch_number = int(match.group(2)) # Extract patch number\n",
    "        else:\n",
    "            print(\"Filename format does not match the expected pattern.\")  \n",
    "\n",
    "        data_dict.append((filename, well_number, patch_number, example.flatten()))\n",
    "\n",
    "    df = pd.DataFrame(data=data_dict, columns=['filename', 'well_number', 'patch_number', 'data'])\n",
    "\n",
    "    df_y = pd.read_csv('train/y_train.csv')\n",
    "    df_y['Unnamed: 0'] = df_y['Unnamed: 0'] + '.npy'\n",
    "\n",
    "    # Create single dataframe with data and labels as lists\n",
    "    merged = pd.merge(df, df_y, how='left', left_on='filename', right_on='Unnamed: 0')\n",
    "    data_columns = [str(i) for i in range(1296)]\n",
    "    labeled_data = merged[data_columns].to_numpy()\n",
    "    # Convert missing labels to all zeros\n",
    "    labeled_data = np.nan_to_num(labeled_data)\n",
    "    merged['labels'] = labeled_data.tolist()\n",
    "    merged = merged.rename(columns={'Unnamed: 0':'label_name'})\n",
    "    merged = merged.fillna(0.0)\n",
    "\n",
    "    data = torch.from_numpy(np.vstack(merged['data'].to_numpy(dtype=np.ndarray)))\n",
    "    # Remove corruputed samples\n",
    "    outliers = ((data.min(dim=1, keepdim=True).values == -999.2500) == True).flatten()\n",
    "\n",
    "    merged = merged.drop(merged.loc[outliers.tolist()].index)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = build_dataframe()\n",
    "valid_dataframe = build_test_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = torch.from_numpy(np.vstack(train_dataframe['data'].to_numpy()))\n",
    "data = torch.nan_to_num(data)\n",
    "labels = torch.from_numpy(np.vstack(train_dataframe['well_number'].to_numpy())).squeeze() - 1\n",
    "\n",
    "valid_data = torch.from_numpy(np.vstack(valid_dataframe['data'].to_numpy()))\n",
    "valid_data = torch.nan_to_num(valid_data)\n",
    "valid_labels = torch.from_numpy(np.vstack(valid_dataframe['well_number'].to_numpy())).squeeze() - 1\n",
    "\n",
    "X_train, X_valid = data, valid_data\n",
    "Y_train, Y_valid = labels, valid_labels\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = torch.tensor(scaler.transform(X_train)).float().reshape(-1, 1, 36, 36)\n",
    "X_valid = torch.tensor(scaler.transform(X_valid)).float().reshape(-1, 1, 36, 36)\n",
    "\n",
    "examples_to_augment = X_train\n",
    "labels_to_augment = Y_train\n",
    "\n",
    "rolled_x, rolled_y = [], []\n",
    "for i in range(1, 36):\n",
    "    rolled_x.append(torch.roll(examples_to_augment, i, dims=3))\n",
    "    rolled_y.append(labels_to_augment)\n",
    "\n",
    "X_train, Y_train = torch.vstack((X_train, *rolled_x)), torch.hstack((Y_train, *rolled_y))\n",
    "\n",
    "flipper = v2.RandomVerticalFlip(1)\n",
    "X_train, Y_train = torch.vstack((X_train, flipper(examples_to_augment))), torch.hstack((Y_train, labels_to_augment))\n",
    "\n",
    "train_dataset = WellsDataset(X_train, Y_train, None)\n",
    "valid_dataset = WellsDataset(X_valid, Y_valid, None)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([349095, 1, 36, 36])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([349095])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2538, 1, 36, 36])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2538])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Individually Normalized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './train/images/'\n",
    "output_dir = './train/processed_images/'\n",
    "for i, filename in enumerate(os.listdir(data_dir)):\n",
    "    example = np.load(data_dir + filename)\n",
    "    scaled = RobustScaler().fit_transform(example)\n",
    "    np.save(output_dir + filename, scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
